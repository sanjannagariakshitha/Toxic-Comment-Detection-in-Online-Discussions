Online news platforms' comment sections facilitate opinion expression and political discourse but are often misused by spammers, haters, and trolls, necessitating costly content moderation.
This project focuses on identifying toxic comments through sentiment analysis to support moderation and understand discussion dynamics. We explore the concept of toxicity and its subclasses, utilizing various deep learning approaches, including KNN, XGBoost, ANN, LSTM, and BiLSTM. 
Our study found XGBoost to be the most accurate algorithm, prompting its use in developing a front-end framework with Flask. 
To address the need for extensive training data in fine-grained comment classification, we propose augmenting data with transfer learning.
Real-world applications include semi-automated comment moderation and troll detection. 
This research aims to enhance the comprehensibility and trustworthiness of moderation tools while addressing challenges and limitations highlighted in recent studies.
